{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvyifanlvlv/PointCounter/blob/master/1st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "l8yBZOZjBmyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "53e2a2a1-6e6e-43ca-f385-8f3a88e26e78"
      },
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 24 02:44:50 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ma9h-ZckCNep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyKcQG2bCnlm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5la7kxkzCrYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "26d3bd0b-1277-41ac-8ee3-27b1d09752d5"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('../')\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5FkdlAg5Cx8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "debd370c-03e8-4ef8-929c-f6f990a8d545"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wxs/keras-mnist-tutorial.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-mnist-tutorial'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Total 26 (delta 0), reused 0 (delta 0), pack-reused 26\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ENADT3HOC3Rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d53a7f75-23a4-4d42-c5ac-966ea3a941c2"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv -P drive/app"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-24 02:49:18--  https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1170 (1.1K) [text/plain]\n",
            "Saving to: ‘drive/app/Titanic.csv’\n",
            "\n",
            "\rTitanic.csv           0%[                    ]       0  --.-KB/s               \rTitanic.csv         100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-01-24 02:49:18 (239 MB/s) - ‘drive/app/Titanic.csv’ saved [1170/1170]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LMtAT6lSC8Sx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxDEPtuyDzRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "b038a576-5b8f-4a7c-fec6-cc833b49aa40"
      },
      "cell_type": "code",
      "source": [
        "!python3 drive/app/test.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "2019-01-24 02:55:23.659967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-24 02:55:23.660460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.00GiB\n",
            "2019-01-24 02:55:23.660496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-24 02:55:23.998897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-24 02:55:23.998991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-24 02:55:23.999009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-24 02:55:23.999322: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-24 02:55:23.999398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.2690 - acc: 0.9159 - val_loss: 0.0556 - val_acc: 0.9824\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0896 - acc: 0.9731 - val_loss: 0.0468 - val_acc: 0.9838\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0696 - acc: 0.9798 - val_loss: 0.0315 - val_acc: 0.9892\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0549 - acc: 0.9835 - val_loss: 0.0302 - val_acc: 0.9890\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0481 - acc: 0.9859 - val_loss: 0.0298 - val_acc: 0.9895\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0425 - acc: 0.9871 - val_loss: 0.0290 - val_acc: 0.9902\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0376 - acc: 0.9890 - val_loss: 0.0331 - val_acc: 0.9891\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0337 - acc: 0.9895 - val_loss: 0.0283 - val_acc: 0.9906\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0302 - acc: 0.9904 - val_loss: 0.0275 - val_acc: 0.9915\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0307 - val_acc: 0.9903\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0278 - acc: 0.9914 - val_loss: 0.0278 - val_acc: 0.9908\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0277 - val_acc: 0.9905\n",
            "Test loss: 0.027719003829242864\n",
            "Test accuracy: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rQ9pjwR0Efm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "cfbe939d-2c5c-4abd-ac5b-bc7c7f0647c1"
      },
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 24 02:57:26 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    66W / 149W |    116MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}